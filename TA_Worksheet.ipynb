{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student's Name and Email Address\n",
    "\n",
    "Boise State University, Department of Chemistry and Biochemistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHEM 324: PChem Lab {-}\n",
    "# Worksheet 3: Transient Absorption Spectroscopy {-}"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:27.709127Z",
     "start_time": "2025-03-28T23:38:27.706843Z"
    }
   },
   "source": [
    "# @title Notebook Setup { display-mode: \"form\" }\n",
    "# Import the main modules used in this worksheet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# The following needs to be the path of the folder with all your datafile in .csv format\n",
    "base_path = '/Users/School/PycharmProjects/PChemLab/TA_Data'"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:27.717339Z",
     "start_time": "2025-03-28T23:38:27.715587Z"
    }
   },
   "source": [
    "# @title Set Local Path { display-mode: \"form\" }\n",
    "# The following needs to be the path of the folder with all your collected data in .csv format\n",
    "# @param {type:\"string\"}\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:27.729967Z",
     "start_time": "2025-03-28T23:38:27.726047Z"
    }
   },
   "source": [
    "# @title Functions to load the data { display-mode: \"form\" }\n",
    "def load_data_to_file_dict(file_dict):\n",
    "    \"\"\"\n",
    "    Load a Transient Absorption Spectroscopy .csv file. \n",
    "    The format of the file should have one row of header, semicolon as separator, and colon as decimal separator\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Add to file_dict a Pandas DataFrame with multiple columns: Laser Delay (in nanoseconds)\n",
    "        and one column for each TA run in units of mOD\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_dict['path']+file_dict['name'],sep=';',decimal='.')\n",
    "    file_dict['data'] = data\n",
    "    return\n",
    "\n",
    "def plot_file_dict(file_dict, yaxis = 'all'):\n",
    "    \"\"\" \n",
    "    Given a file dictionary, plot one of the transient absorption curves (or the average)\n",
    "    versus the laser delay\n",
    "    \"\"\"\n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    if yaxis == 'all':\n",
    "        for column in file_dict['data'].columns:\n",
    "            if column == 'Laser Delay [ns]' : continue\n",
    "            plt.plot(file_dict['data']['Laser Delay [ns]'],file_dict['data'][column],label=column)\n",
    "    else : \n",
    "        if yaxis in file_dict['data'].columns:\n",
    "            plt.plot(file_dict['data']['Laser Delay [ns]'],file_dict['data'][yaxis],label=yaxis)\n",
    "        else:\n",
    "            print('ERROR: specified yaxis is not in the read data')\n",
    "    plt.ylabel('Transient Absorption [mOD]')\n",
    "    plt.xlabel('Laser Delay [ns]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_file_list(file_list,yaxis = 'TA1 [mOD]'):\n",
    "    \"\"\"\n",
    "    Given a list of dictionary files, plot one of the transient absorption curves (or the average)\n",
    "    versus the laser delay for each of the files\n",
    "    \"\"\"\n",
    "    #\n",
    "    fig, ax = plt.subplots()\n",
    "    #\n",
    "    for file_dict in file_list : \n",
    "        (file_dict)\n",
    "        plt.plot(file_dict['data']['Laser Delay [ns]'],file_dict['data'][yaxis],label=file_dict['label'])\n",
    "    plt.ylabel('Transient Absorption [mOD]')\n",
    "    plt.xlabel('Laser Delay [ns]')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:27.742606Z",
     "start_time": "2025-03-28T23:38:27.738183Z"
    }
   },
   "source": [
    "# @title Utilities to analyze the data { display-mode: \"form\" }\n",
    "def exponential(t, a, tau, o):\n",
    "    \"\"\" \n",
    "    Function that returns an exponentially decaying function plus offset\n",
    "    f(t) = o + a*e^(-t/tau)\n",
    "\n",
    "    input variables\n",
    "    t: input value (units of time)\n",
    "    a: amplitude (units of absorbance or concentration)\n",
    "    tau: lifetime (units of time)\n",
    "    o: offset (units of absorbance or concentration)\n",
    "    \"\"\"\n",
    "    if tau < 1.e-10 : \n",
    "        print('ERROR: choose a value of tau greater than zero')\n",
    "        return 0.\n",
    "    return a * np.exp(-t/tau) + o\n",
    "\n",
    "def fit_ta_data(file_dict, yaxis = 'TA1 [mOD]', verbose = False, semilog = False):\n",
    "    \"\"\" \n",
    "    Perform the fit of transient absorption decay curves using an exponential \n",
    "    functions plus offset. \n",
    "\n",
    "    Input parameters: \n",
    "    file_dict: a dictionary with information on the file with the data (path and name) and\n",
    "               adjustable parameters related to the fit:\n",
    "               time_skip : initial transient regime to remove from the fit\n",
    "               C0_guess, k_guess, offset_guess: starting guess of fitting parameters\n",
    "    yaxis : the column of the dataframe to use for the fit\n",
    "    verbose : if True plot the filtered data and the corresponding fit\n",
    "    semilog : if True, plot in semilogy scale\n",
    "\n",
    "    Action: \n",
    "           Filter the data by removing the initial time_skip part of the curve\n",
    "           Fit according to an exponential decay\n",
    "           Save the optimized values of the parameters and their standard errors in file_dict\n",
    "           Save the fitted curve in the file_dict['data'] DataFrame\n",
    "    \"\"\"   \n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    xaxis = 'Laser Delay [ns]'\n",
    "        \n",
    "    file_dict['filtered_data'] = file_dict['data'][file_dict['data']['Laser Delay [ns]']>file_dict['time_skip']].copy()\n",
    "    x = file_dict['filtered_data'][xaxis]\n",
    "    y = file_dict['filtered_data'][yaxis]\n",
    "\n",
    "    funct = exponential\n",
    "    p0 = (file_dict['DA0_guess'],file_dict['tau_guess'],file_dict['offset_guess'])\n",
    "    params, cv = scipy.optimize.curve_fit(funct,x,y,p0)\n",
    "\n",
    "    file_dict['DA0'] = params[0]\n",
    "    file_dict['DA0_SE'] = np.sqrt(cv[0,0])\n",
    "    file_dict['tau'] = params[1]\n",
    "    file_dict['tau_SE'] = np.sqrt(cv[1,1])\n",
    "    file_dict['offset'] = params[2] \n",
    "    file_dict['offset_SE'] = np.sqrt(cv[2,2])\n",
    "\n",
    "    file_dict['filtered_data']['TA_fitted'] = funct(x,params[0],params[1],params[2])\n",
    "\n",
    "    if verbose :\n",
    "        if semilog :\n",
    "            plt.semilogy(x,y,label=yaxis)\n",
    "            plt.semilogy(x,funct(x,params[0],params[1],params[2]),label='Fit')\n",
    "        else :\n",
    "            plt.plot(x,y,label=yaxis)\n",
    "            plt.plot(x,funct(x,params[0],params[1],params[2]),label='Fit')\n",
    "        plt.ylabel('Transient Absorption [mOD]')\n",
    "        plt.xlabel('Laser Delay [ns]')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below are incomplete and will need to be completed by the student."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:27.753996Z",
     "start_time": "2025-03-28T23:38:27.750950Z"
    }
   },
   "source": [
    "def calc_average_TA(file_dict):\n",
    "    \"\"\"\n",
    "    Average all the TA runs recorded in a TA .csv file.\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Create a new column in the file_dict['data'] component of the input with the average\n",
    "        of the TA runs recorded in the file\n",
    "    \"\"\"\n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    columns = file_dict['data'].columns.drop('Laser Delay [ns]')\n",
    "    if 'TAaverage' in file_dict['data'].columns: \n",
    "        columns = columns.drop('TAaverage')\n",
    "    # the variable columns is a list that contains the columns of the dataframe you need to average\n",
    "    file_dict['data']['TAaverage'] = file_dict['data'][columns].mean(axis=1)\n",
    "    return\n",
    "\n",
    "def calc_max_TA(file_dict):\n",
    "    \"\"\"\n",
    "    Given a file dictionary with the average TA, find the maximum value of the transient absorption \n",
    "    and the Laser Delay at which this value occurs\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        \n",
    "    \"\"\"\n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    if not ('TAaverage' in file_dict['data'].columns): \n",
    "        calc_average_TA(file_dict)\n",
    "\n",
    "\n",
    "    max_index = file_dict['data']['TAaverage'].idxmax()\n",
    "\n",
    "\n",
    "    file_dict['TAmax'] = file_dict['data']['TAaverage'].iloc[max_index]\n",
    "    file_dict['LD_TAmax'] = file_dict['data']['Laser Delay [ns]'].iloc[max_index]\n",
    "    return"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Average of TA Spectra {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualize the chemical structures of ZnTPP (CAS 14074-80-7) and comment on why this molecule is absorbing in the visible.\n",
    "* Load the TA spectra for the first concentration of ZnTPP into a Pandas DataFrame. Average the scans and save them as an extra column in the DataFrame. \n",
    "* Plot the different TA spectra for the first concentration of ZnTPP together with the averaged spectra. You will need to present one figure containing all scans and the averaged one. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:40.081884Z",
     "start_time": "2025-03-28T23:38:40.079362Z"
    }
   },
   "source": [
    "file1 = {'path':path, 'name':'TA_traces.csv', 'label':'Run1', '[ZnTPP]': 0.2, '[C70]':0., 'time_skip':0, 'DA0_guess':1., 'tau_guess':1., 'offset_guess':0.}"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: TA Spectra for Varying ZnTPP Concentrations {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load and average the TA spectra for the different ZnTPP concentrations. Explicitly report all the constants and/or known experimental values that you will need in your following analyses. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:27.813565Z",
     "start_time": "2025-03-28T23:38:27.764787Z"
    }
   },
   "source": [
    "file1 = {'path':path, 'name':'TA_traces.csv', 'label':'Run1', '[ZnTPP]': 0.2, '[C70]':0., 'time_skip':0, 'DA0_guess':1., 'tau_guess':1., 'offset_guess':0.}\n",
    "file2 = {'path':path, 'name':'TA_traces.csv', 'label':'Run2', '[ZnTPP]': 0.4, '[C70]':0., 'time_skip':0, 'DA0_guess':1., 'tau_guess':1., 'offset_guess':0.}\n",
    "file3 = {'path':path, 'name':'TA_traces.csv', 'label':'Run3', '[ZnTPP]': 0.8, '[C70]':0., 'time_skip':0, 'DA0_guess':1., 'tau_guess':1., 'offset_guess':0.}\n",
    "\n",
    "experiment1 = [file1, file2, file3]\n",
    "\n",
    "# the following loop will compute the avearge of each file in the list above\n",
    "# NOTE: the function calc_average_TA is incomplete and will need you to implement the calculation of the average TA\n",
    "for file in experiment1:\n",
    "    calc_average_TA(file)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/School/PycharmProjects/PChemLab/TA_DataTA_traces.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# the following loop will compute the avearge of each file in the list above\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# NOTE: the function calc_average_TA is incomplete and will need you to implement the calculation of the average TA\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m experiment1:\n\u001B[0;32m---> 10\u001B[0m     calc_average_TA(file)\n",
      "Cell \u001B[0;32mIn[42], line 13\u001B[0m, in \u001B[0;36mcalc_average_TA\u001B[0;34m(file_dict)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mAverage all the TA runs recorded in a TA .csv file.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m    of the TA runs recorded in the file\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m file_dict): \n\u001B[0;32m---> 13\u001B[0m     load_data_to_file_dict(file_dict)\n\u001B[1;32m     14\u001B[0m columns \u001B[38;5;241m=\u001B[39m file_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLaser Delay [ns]\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTAaverage\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m file_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcolumns: \n",
      "Cell \u001B[0;32mIn[40], line 14\u001B[0m, in \u001B[0;36mload_data_to_file_dict\u001B[0;34m(file_dict)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_data_to_file_dict\u001B[39m(file_dict):\n\u001B[1;32m      3\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m    Load a Transient Absorption Spectroscopy .csv file. \u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m    The format of the file should have one row of header, semicolon as separator, and colon as decimal separator\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m        and one column for each TA run in units of mOD\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m     data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(file_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpath\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m+\u001B[39mfile_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m],sep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m'\u001B[39m,decimal\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m     file_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m get_handle(\n\u001B[1;32m   1881\u001B[0m     f,\n\u001B[1;32m   1882\u001B[0m     mode,\n\u001B[1;32m   1883\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1884\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1885\u001B[0m     memory_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[1;32m   1886\u001B[0m     is_text\u001B[38;5;241m=\u001B[39mis_text,\n\u001B[1;32m   1887\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding_errors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1888\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m   1889\u001B[0m )\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    874\u001B[0m             handle,\n\u001B[1;32m    875\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m    876\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[1;32m    877\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[1;32m    878\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    879\u001B[0m         )\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/School/PycharmProjects/PChemLab/TA_DataTA_traces.csv'"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the averaged TA spectra for the different ZnTPP concentrations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to use the function plot_file_list() and specify to plot the column with the average TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What effects on the signal do you observe for different concentrations?\n",
    "* How can those effects be explained by setup parameters and/or reaction chemistry? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Max Signal and Time Constants for Varying ZnTPP Concentrations {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each averaged TA spectra, compute the maximum transient absorption and the delay at which it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following loop will compute the maximum of each averaged TA spectrum and the delay at which it occurs\n",
    "# NOTE: this function is incomplete and will need you to implement the actual calculations\n",
    "for file in experiment1:\n",
    "    calc_max_TA(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit the portion of the averaged TA spectra after the peak with an exponential curve with a vertical offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following loop will compute the maximum of each averaged TA spectrum and the delay at which it occurs\n",
    "# NOTE: for this function to work you need to have the correct TAaverage column in your data (from Task 1)\n",
    "for file in experiment1:\n",
    "    fit_ta_data(file,yaxis='TAaverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Report a table with the quantities computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming that you have succesfully completed the steps above, you can convert your list of files into a dataframe\n",
    "# which should contain columns with the quantities computed above\n",
    "experiment1_data = pd.DataFrame(experiment1)\n",
    "experiment1_data[['[ZnTPP]','TAmax','LD_TAmax','tau','offset']].to_markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the single exponential fit adequate? Is a Y-axis offset needed as a free fit parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENTS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Are there any trends in the maximum TA, delay of the peak, and lifetime? Briefly comment on possible explanations for trends or lack of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR COMMENTS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Lifetime and Offset for Varying C70 Concentrations {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load and average the TA spectra for the different C70 concentrations. Explicitly report all the constants and/or known experimental values that you will need in your following analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Plot the averaged TA spectra for the different C70 concentrations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit each averaged TA spectra with an expontial curve plus Y-offset (similar to the task before). Report the maximum TA, lifetime, and offset for the different C70 \n",
    "concentrations.\n",
    "* Is the Y-offset important for these experiments? Give a brief explanation of its origin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform a linear fit of the inverse lifetimes (a.k.a. the effective reaction constants) as a function of the concentration of C70. \n",
    "* From the slope of the linear fit, compute the reaction constant $k_q$ and report it using the correct units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is used to allow Google Colab to install the tools to convert the notebook to a pdf file\n",
    "# Un-comment the following lines when you are ready to export the pdf \n",
    "#!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
    "#!pip install pypandoc"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T23:38:27.823717Z",
     "start_time": "2025-03-28T23:25:34.198815Z"
    }
   },
   "source": [
    "# Use this command to convert the finished worksheet into a pdf \n",
    "# NOTE : you may want to change the path of the file, if you are working in a different folder of the Google Drive\n",
    "#!jupyter nbconvert --no-input --to PDF \"/content/drive/MyDrive/Colab Notebooks/TA_Worksheet.ipynb\""
   ],
   "outputs": [],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
